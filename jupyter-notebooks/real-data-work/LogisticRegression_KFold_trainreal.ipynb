{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and testing on real data (10 Fold CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading real data\n",
    "p_0130 = sp.sparse.load_npz('../../data/real/20x20x20/run_0130_pDisc.npz')\n",
    "C_0130 = sp.sparse.load_npz('../../data/real/20x20x20/run_0130_CDisc.npz')\n",
    "junk_0130 = sp.sparse.load_npz('../../data/real/20x20x20/run_0130_junkDisc.npz')\n",
    "p_0210 = sp.sparse.load_npz('../../data/real/20x20x20/run_0210_pDisc.npz')\n",
    "C_0210 = sp.sparse.load_npz('../../data/real/20x20x20/run_0210_CDisc.npz')\n",
    "junk_0210 = sp.sparse.load_npz('../../data/real/20x20x20/run_0210_junkDisc.npz')\n",
    "\n",
    "p_real = sp.sparse.vstack([p_0130, p_0210], format='csr')\n",
    "C_real = sp.sparse.vstack([C_0130, C_0210], format='csr')\n",
    "junk_real = sp.sparse.vstack([junk_0130, junk_0210], format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating labels\n",
    "#protons 0s\n",
    "#carbons 1s\n",
    "#junk 1s\n",
    "p_real_labels = np.zeros((p_real.shape[0],))\n",
    "C_real_labels = np.ones((C_real.shape[0],))\n",
    "junk_real_labels = np.ones((junk_real.shape[0],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proton vs. Carbon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pC_real = sp.sparse.vstack([p_real, C_real], format='csr')\n",
    "pC_real_labels = np.hstack((p_real_labels, C_real_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.87128713  0.82178218  0.87128713  0.89        0.83        0.89        0.79\n",
      "  0.87        0.83        0.83      ]\n",
      "Accuracy: 0.85 (+/- 0.06)\n"
     ]
    }
   ],
   "source": [
    "reg = 0.001\n",
    "lr_pC = LogisticRegression(C=reg)\n",
    "scores = cross_val_score(lr_pC, pC_real, pC_real_labels, cv=10)\n",
    "#scores = cross_val_score(lr_pC, pC_real, pC_real_labels, cv=10, scoring='f1')\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.849451645065\n"
     ]
    }
   ],
   "source": [
    "pC_pred = cross_val_predict(lr_pC, pC_real, pC_real_labels, cv=10)\n",
    "print(metrics.accuracy_score(pC_real_labels, pC_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.85      0.93      0.89       663\n",
      "        1.0       0.84      0.69      0.76       340\n",
      "\n",
      "avg / total       0.85      0.85      0.85      1003\n",
      "\n",
      "[[617  46]\n",
      " [105 235]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(pC_real_labels, pC_pred))\n",
    "print(metrics.confusion_matrix(pC_real_labels, pC_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proton vs. Junk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# proton 0s\n",
    "# junk 1s\n",
    "pjunk_real = sp.sparse.vstack([p_real, junk_real], format='csr')\n",
    "pjunk_real_labels = np.hstack((p_real_labels, junk_real_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.84322034  0.83050847  0.86864407  0.82978723  0.86808511  0.87659574\n",
      "  0.82905983  0.85042735  0.84615385  0.8034188 ]\n",
      "Accuracy: 0.84 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "reg = 0.001\n",
    "lr_pjunk = LogisticRegression(C=reg)\n",
    "scores = cross_val_score(lr_pjunk, pjunk_real, pjunk_real_labels, cv=10)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.844614729672\n"
     ]
    }
   ],
   "source": [
    "pjunk_pred = cross_val_predict(lr_pjunk, pjunk_real, pjunk_real_labels, cv=10)\n",
    "print(metrics.accuracy_score(pjunk_real_labels, pjunk_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.50      0.64       663\n",
      "        1.0       0.83      0.98      0.90      1686\n",
      "\n",
      "avg / total       0.85      0.84      0.83      2349\n",
      "\n",
      "[[ 330  333]\n",
      " [  32 1654]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(pjunk_real_labels, pjunk_pred))\n",
    "print(metrics.confusion_matrix(pjunk_real_labels, pjunk_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proton vs. Carbon+Junk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pCjunk_real = sp.sparse.vstack([p_real, C_real, junk_real], format='csr')\n",
    "pCjunk_real_labels = np.hstack((p_real_labels, C_real_labels, junk_real_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg = 0.001\n",
    "lr_pCjunk = LogisticRegression(C=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.78148148  0.78148148  0.84444444  0.82527881  0.866171    0.86988848\n",
      "  0.83208955  0.83955224  0.85074627  0.81343284]\n",
      "Accuracy: 0.83 (+/- 0.06)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(lr_pCjunk, pCjunk_real, pCjunk_real_labels, cv=10)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.830420230569\n"
     ]
    }
   ],
   "source": [
    "pCjunk_pred = cross_val_predict(lr_pCjunk, pCjunk_real, pCjunk_real_labels, cv=10)\n",
    "print(metrics.accuracy_score(pCjunk_real_labels, pCjunk_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.40      0.53       663\n",
      "        1.0       0.83      0.97      0.90      2026\n",
      "\n",
      "avg / total       0.83      0.83      0.81      2689\n",
      "\n",
      "[[ 262  401]\n",
      " [  55 1971]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(pCjunk_real_labels, pCjunk_pred))\n",
    "print(metrics.confusion_matrix(pCjunk_real_labels, pCjunk_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proton vs. Carbon vs. Junk (multiclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#protons 0\n",
    "#carbons 1\n",
    "#junk 2\n",
    "\n",
    "#create junk 2s labels\n",
    "junkMC_real_labels = np.full(junk_real_labels.shape, 2)\n",
    "\n",
    "MC_real = sp.sparse.vstack([p_real, C_real, junk_real], format='csr')\n",
    "MC_real_labels = np.hstack((p_real_labels, C_real_labels, junkMC_real_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = 0.001\n",
    "lr_MC = LogisticRegression(C=reg, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.74814815  0.7         0.77777778  0.78066914  0.79925651  0.81040892\n",
      "  0.75        0.77985075  0.76492537  0.69776119]\n",
      "Accuracy: 0.76 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(lr_MC, MC_real, MC_real_labels, cv=10)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.760877649684\n"
     ]
    }
   ],
   "source": [
    "MC_pred = cross_val_predict(lr_MC, MC_real, MC_real_labels, cv=10)\n",
    "print(metrics.accuracy_score(MC_real_labels, MC_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.50      0.63       663\n",
      "        1.0       0.60      0.33      0.42       340\n",
      "        2.0       0.76      0.95      0.85      1686\n",
      "\n",
      "avg / total       0.76      0.76      0.74      2689\n",
      "\n",
      "[[ 330   15  318]\n",
      " [  42  111  187]\n",
      " [  21   60 1605]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(MC_real_labels, MC_pred))\n",
    "print(metrics.confusion_matrix(MC_real_labels, MC_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
